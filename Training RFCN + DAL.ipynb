{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCN + DAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "upKHi5xOcyvu"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, History, Callback\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_J_UWdyxfA3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN38j4Mzc6_K"
      },
      "source": [
        "x_train = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_train_image.npy\")\n",
        "r_train = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_train_region.npy\")\n",
        "b_train = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_train_boundary.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4PopurdDy8"
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis=3).astype('float32')\n",
        "r_train = np.expand_dims(r_train, axis=3).astype('float32')\n",
        "b_train = np.expand_dims(b_train, axis=3).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bD4kBD-dMmI"
      },
      "source": [
        "def residual_block(x, filter_amount, filter_size):\n",
        "    residual = BatchNormalization()(x)\n",
        "    residual = Activation(activation = 'relu')(residual)\n",
        "    residual = Conv2D(filters = filter_amount, kernel_size = filter_size, padding = 'same', strides = (1,1))(residual)\n",
        "    residual = Dropout(0.2)(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    residual = Activation(activation = 'relu')(residual)\n",
        "    residual = Conv2D(filters = filter_amount, kernel_size = filter_size, padding = 'same', strides = (1,1))(residual)\n",
        "    residual = Dropout(0.2)(residual)\n",
        "    \n",
        "    res_shortcut = Conv2D(filters = filter_amount, kernel_size = 1, padding = 'same', strides = (1,1))(x)\n",
        "    res_shortcut = BatchNormalization()(res_shortcut)\n",
        "    \n",
        "    residual = add([res_shortcut, residual])\n",
        "    return residual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B21QqFiMpBDv"
      },
      "source": [
        "def residual_block2(x, y, filter_amount, filter_size):\n",
        "    residual = Concatenate()([x, y])\n",
        "    residual = BatchNormalization()(residual)\n",
        "    residual = Activation(activation = 'relu')(residual)\n",
        "    residual = Conv2D(filters = filter_amount, kernel_size = filter_size, padding = 'same', strides = (1,1))(residual)\n",
        "    residual = Dropout(0.2)(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    residual = Activation(activation = 'relu')(residual)\n",
        "    residual = Conv2D(filters = filter_amount, kernel_size = filter_size, padding = 'same', strides = (1,1))(residual)\n",
        "    residual = Dropout(0.2)(residual)\n",
        "    \n",
        "    res_shortcut = Conv2D(filters = filter_amount, kernel_size = 1, padding = 'same', strides = (1,1))(x)\n",
        "    res_shortcut = BatchNormalization()(res_shortcut)\n",
        "    \n",
        "    residual = add([res_shortcut, residual])\n",
        "    return residual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCJ3rZfiduQ6"
      },
      "source": [
        "def rfcn(inputshape, filter_amount, filter_size):\n",
        "    #Encoder\n",
        "    inputs = Input(shape = inputshape)\n",
        "    res1 = residual_block(inputs, filter_amount[0], filter_size)\n",
        "    down_conv1 = Conv2D(filters = filter_amount[1], kernel_size = 2, padding = 'valid', strides = (2,2))(res1)\n",
        "    res2 = residual_block(down_conv1, filter_amount[1], filter_size)\n",
        "    down_conv2 = Conv2D(filters = filter_amount[2], kernel_size = 2, padding = 'valid', strides = (2,2))(res2)\n",
        "    res3 = residual_block(down_conv2, filter_amount[2], filter_size)\n",
        "    down_conv3 = Conv2D(filters = filter_amount[3], kernel_size = 2, padding = 'valid', strides = (2,2))(res3)\n",
        "    \n",
        "    #Bridge\n",
        "    res4 = residual_block(down_conv3, filter_amount[3], filter_size)\n",
        "    up_conv1 = Conv2DTranspose(filters = filter_amount[2], kernel_size = 2, padding = 'valid', strides = (2,2))(res4)\n",
        "    \n",
        "    #Decoder\n",
        "    res5 = residual_block2(up_conv1, res3, filter_amount[2], filter_size)\n",
        "    up_conv2 = Conv2DTranspose(filters = filter_amount[1], kernel_size = 2, padding = 'valid', strides = (2,2))(res5)\n",
        "    res6 = residual_block2(up_conv2, res2, filter_amount[1], filter_size)\n",
        "    up_conv3 = Conv2DTranspose(filters = filter_amount[0], kernel_size = 2, padding = 'valid', strides = (2,2))(res6)\n",
        "    res6 = residual_block2(up_conv3, res1, filter_amount[0], filter_size)\n",
        "    \n",
        "    #Region\n",
        "    conv1 = Conv2D(filters = filter_amount[0], kernel_size = 3, padding = 'same', strides = (1,1))(res6)\n",
        "    do = Dropout(0.2)(conv1)\n",
        "    output_region = Conv2D(filters = 1, kernel_size = 1, activation='sigmoid', kernel_initializer='he_normal', name = 'region_output')(do)\n",
        "    \n",
        "    #Boundary\n",
        "    conv2 = Conv2D(filters = filter_amount[0], kernel_size = 3, padding = 'same', strides = (1,1))(res6)\n",
        "    do = Dropout(0.2)(conv2)\n",
        "    output_boundary = Conv2D(filters = 1, kernel_size = 1, activation='sigmoid', kernel_initializer='he_normal', name = 'boundary_output')(do)\n",
        "    \n",
        "    return Model(inputs = [inputs], outputs=[output_region, output_boundary])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_V8iei5dwg6"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI7SsgridzRE"
      },
      "source": [
        "def binary_focal_loss(gamma, alpha, beta):\n",
        "    \"\"\"\n",
        "    Binary form of focal loss.\n",
        "         Focal loss for binary classification problems\n",
        "    \n",
        "    focal_loss(p_t) = -alpha_t * (1 - p_t)**gamma * log(p_t)\n",
        "        where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
        "    References:\n",
        "        https://arxiv.org/pdf/1708.02002.pdf\n",
        "    Usage:\n",
        "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
        "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "\n",
        "    def binary_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        y_true shape need be (None,1)\n",
        "        y_pred need be compute after sigmoid\n",
        "        \"\"\"\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n",
        "    \n",
        "        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n",
        "        fl = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n",
        "        fl = K.mean(fl)\n",
        "        fl = beta * fl\n",
        "        return fl\n",
        "    return binary_focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5itU3IFusOnx"
      },
      "source": [
        "filter_amount = [32, 64, 128, 256]\n",
        "filter_size = 3\n",
        "model = rfcn(inputshape = (192, 256, 1), filter_amount = filter_amount, filter_size = filter_size)\n",
        "model_checkpoint = ModelCheckpoint('200 RFNC + DAL (Region 0.6, Boundary 0.4).h5', monitor='loss', save_best_only=True)\n",
        "model.compile(optimizer = Adam(lr = 0.001), \n",
        "              loss = {'region_output' : binary_focal_loss(gamma = 2., alpha = 0.25, beta = 0.6), 'boundary_output' : binary_focal_loss(gamma = 2., alpha = 0.25, beta = 0.4)}, \n",
        "              metrics = {'region_output' : dice_coef, 'boundary_output' : dice_coef})\n",
        "history_model = model.fit([x_train], [r_train, b_train], batch_size=48, epochs=1000, verbose=1, shuffle = True, callbacks=[model_checkpoint])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZpqd6T5Xrsf",
        "collapsed": true
      },
      "source": [
        "print(history_model.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J6LwkTiZX7O"
      },
      "source": [
        "epoch_count = range(1, len(history_model.history['loss']) + 1)\n",
        "plt.plot(epoch_count, history_model.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCH3LuFyMsHK"
      },
      "source": [
        "epoch_count = range(1, len(history_model.history['region_output_loss']) + 1)\n",
        "plt.plot(epoch_count, history_model.history['region_output_loss'])\n",
        "plt.title('Region Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQNa4_GvM0CB"
      },
      "source": [
        "epoch_count = range(1, len(history_model.history['boundary_output_loss']) + 1)\n",
        "plt.plot(epoch_count, history_model.history['boundary_output_loss'])\n",
        "plt.title('Boundary Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYViy06iZtgP"
      },
      "source": [
        "plt.plot(epoch_count, history_model.history['region_output_dice_coef'])\n",
        "plt.plot(epoch_count, history_model.history['boundary_output_dice_coef'])\n",
        "plt.legend(['Region Dice Score', 'Boundary Dice Score'])\n",
        "plt.title('Training Dice Score')\n",
        "plt.ylabel('Dice SCore')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6F5GhG4sL-1"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V0FErQutCWG"
      },
      "source": [
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh22Hx2RgoCr"
      },
      "source": [
        "x_test = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_test_image.npy\")\n",
        "r_test = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_test_region.npy\")\n",
        "b_test = np.load(\"/content/drive/MyDrive/Tesis Yolla/Output/200 files 1/200_test_boundary.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT3h77nugoC2"
      },
      "source": [
        "x_test = np.expand_dims(x_test, axis=3).astype('float32')\n",
        "r_test = np.expand_dims(r_test, axis=3).astype('float32')\n",
        "b_test = np.expand_dims(b_test, axis=3).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gKfnCQg4x9"
      },
      "source": [
        "result = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5l8ZO7oN53A"
      },
      "source": [
        "gabung = []\n",
        "for i in range(len(r_test)):\n",
        "  g = result[0][i] + result[1][i]\n",
        "  # g = asarray(g)\n",
        "  g[g < 1] = 0\n",
        "  g[g >= 1] = 1\n",
        "  gabung.append(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80nfsxvKnpm"
      },
      "source": [
        "gabung2 = []\n",
        "for i in range(len(r_test)):\n",
        "  g = result[0][i] + result[1][i]\n",
        "  # g = asarray(g)\n",
        "  # g[g < 1] = 0\n",
        "  # g[g >= 1] = 1\n",
        "  gabung2.append(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF6DXNkkhFdM"
      },
      "source": [
        "dice_r = dice_coef(result[0], r_test)\n",
        "precision_r = precision_m(result[0], r_test)\n",
        "recall_r = recall_m(result[0], r_test)\n",
        "\n",
        "dice_b = dice_coef(result[1], b_test)\n",
        "precision_b = precision_m(result[1], b_test)\n",
        "recall_b = recall_m(result[1], b_test)\n",
        "\n",
        "dice_g = dice_coef(gabung, r_test)\n",
        "precision_g = precision_m(gabung, r_test)\n",
        "recall_g = recall_m(gabung, r_test)\n",
        "\n",
        "dice_g2 = dice_coef(gabung2, r_test)\n",
        "precision_g2 = precision_m(gabung2, r_test)\n",
        "recall_g2 = recall_m(gabung2, r_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im5ZPts5hz0F"
      },
      "source": [
        "with tf.compat.v1.Session() as sess:\n",
        "  print('----Region----\\nDice Coef Score\\t: ' +str(dice_r.numpy())+ '\\nPrecision\\t: ' +str(precision_r.numpy())+ '\\nRecall\\t\\t: '+str(recall_r.numpy()))\n",
        "  print('\\n----Boundary----\\nDice Coef Score\\t: ' +str(dice_b.numpy())+ '\\nPrecision\\t: ' +str(precision_b.numpy())+ '\\nRecall\\t\\t: '+str(recall_b.numpy()))\n",
        "  print('\\n----Gabungan----\\nDice Coef Score\\t: ' +str(dice_g.numpy())+ '\\nPrecision\\t: ' +str(precision_g.numpy())+ '\\nRecall\\t\\t: '+str(recall_g.numpy()))\n",
        "  print('\\n----Gabungan 2----\\nDice Coef Score\\t: ' +str(dice_g2.numpy())+ '\\nPrecision\\t: ' +str(precision_g2.numpy())+ '\\nRecall\\t\\t: '+str(recall_g2.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50kPM02tNeC_"
      },
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "for i in range(len(result[0])):\n",
        "  plt.subplot(8,5,i+1),plt.imshow(result[0][i].reshape(192,256),cmap = 'gray')\n",
        "  plt.title(i+1), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}